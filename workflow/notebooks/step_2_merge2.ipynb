{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Merge intersect and impute data for analysis \n",
    "project name is <soyadapt_data_analysis>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "1. Step 1 Startfile. If you haven't already, then go to step_1_startfile to set up the project. []\n",
    "2. Merge data for analysis \n",
    "\n",
    "Section 1.\n",
    "Here im going to merge the data and create a file the is the intersect of the data.\n",
    "\n",
    "Section 2.\n",
    "Then im going to go on to impute the missing data with Beagle using a reference panel which is the CCA accessions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will all happen on the GenomeDK cluster. \n",
    "i will create a environment for step 2. called merge_env\n",
    "any programs used will be stated here and the environment will also be backed up in soyadapt_data_analysis/workflow/envs\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge_env.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "from pgpipe import four_gamete, vcf_split_pysam, vcf_to_ima, vcf_filter, vcf_calc, vcf_sampler, vcf_phase, stat_sampler, vcf_split, vcf_utilities, vcf_to_treemix, model_creator\n",
    "from pgpipe.logging_module import initLogger\n",
    "from pgpipe.informative_loci_filter import filter_bed_regions\n",
    "from pgpipe.subtract_bed import filter_stat\n",
    "import pysam\n",
    "\n",
    "print (\"Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define project name\n",
    "#project_name = 'projectname'\n",
    "project_name = 'soyadapt_data_analysis' # [ ] \n",
    "\n",
    "import os.path\n",
    "path = '/Users/josephinelovemachine'\n",
    "full_path = os.path.expanduser(path)\n",
    "print (full_path)\n",
    "# set home directory\n",
    "# ~/<projectname>/\n",
    "home_dir = os.path.join( full_path, project_name)\n",
    "print (home_dir)\n",
    "print (\"home directory defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up directories and filepaths, run on all restarts\n",
    "config_dir = home_dir + '/config/'\n",
    "results_dir = home_dir + '/results/'\n",
    "workflow_dir = home_dir + '/workflow/' \n",
    "notebook_dir = workflow_dir + '/notebooks/' #WHE RE THIS NOTEBOOK SHOULD BE [ ]\n",
    "# my working dir is where my data is ~/project_name/resources/\n",
    "work_dir = home_dir + '/resources/'\n",
    "#start data files:'\n",
    "data_dir= work_dir +'start_data/' # my main_vcf_data is here\n",
    "#generated data files:\n",
    "data_generated = work_dir + 'generated_data/'\n",
    "#generated data files:\n",
    "logfile = data_generated+'logfiles/'\n",
    "\n",
    "#Define start data name and location:\n",
    "# data names are set to data _ name _ *** (e.g. data_name_snp)\n",
    "# data locations are set to data _ *** _ datatype (e.g. data_snp_vcf)\n",
    "#Which data do you want to use?\n",
    "data_name_snp = 'soysnp50k' \n",
    "data_snp_vcf = data_dir+'soysnp50k.vcf.gz' \n",
    "data_name_test = 'test_data' \n",
    "data_test_vcf = data_dir+'test_data.vcf.gz' \n",
    "data_name_intersection = 'intersection_data'\n",
    "data_intersection_vcf = data_dir+'intersection_data.vcf.gz' \n",
    "data_name_imputed = 'imputed_data'\n",
    "data_imputed_vcf = data_dir+'imputed_data.vcf.gz' \n",
    "\n",
    "# ADDED Metadata from start\n",
    "#chromosomes list\n",
    "list_vcf_name_chr = data_dir+'soysnp50k_list_vcf_name_chr'\n",
    "# string of all 20 chromosomes named chr\n",
    "chr_all = data_dir+'chr.txt' \n",
    "# The 50k snps list \n",
    "list_snp_locations_50k = data_dir+'soysnp50k_ist_snp_locations_50k'\n",
    "# metadata list:\n",
    "list_vcf_name_country = data_dir+'soysnp50k_list_vcf_name_country'\n",
    "list_vcf_name_maturitygroup = data_dir+'soysnp50k_list_vcf_name_maturitygroup'\n",
    "#list of accessions + population(CCA/SA/Founders) + country + maturity group\n",
    "list_vcf_name_collected = data_dir+'soysnp50k_list_vcf_name_collected'\n",
    "#data files lists so they are named accordingly when generated or added to the project:\n",
    "list_vcf_name_sa= data_dir+'soysnp50k_list_vcf_name_sa'\n",
    "list_vcf_name_cca= data_dir+'soysnp50k_list_vcf_name_cca'\n",
    "list_vcf_name_founders= data_dir+'soysnp50k_list_vcf_name_founders'\n",
    "\n",
    "loci=50000\n",
    "# print check directories and files\n",
    "print(work_dir)\n",
    "print(data_dir)\n",
    "print(data_generated)\n",
    "print(logfile)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Software packages\n",
    " \n",
    "1.1.1 Download and install the software packages \n",
    "Required software packages are listed below with the versions used in this protocol. However, using the latest versions is recommended.\n",
    "\n",
    "    BCFtools v1.7 (or later version) http://www.htslib.org/download/\n",
    "    R v3.4.1 (or later version) https://www.r-project.org/\n",
    "    R package data.table https://github.com/Rdatatable/data.table/wiki/Installation\n",
    "    R package sm https://cran.r-project.org/package=sm\n",
    "    Eagle v2.3.5 https://data.broadinstitute.org/alkesgroup/Eagle/\n",
    "    Beagle v4.1 beagle.27Jan18.7e1.jar https://faculty.washington.edu/browning/beagle/b4_1.html\n",
    "    Beagle bref bref.27Jan18.7e1.jar https://faculty.washington.edu/browning/beagle/bref.27Jan18.7e1.jar\n",
    "\n",
    " \n",
    "\n",
    "1.1.2 Export the paths\n",
    "Once installed, export the correct paths to environment variable PATH:\n",
    "Command\n",
    "echo PATH=/path/to/bcftools/:/path/to/R/:/path/to/eagle/:$PATH \\\n",
    ">> $HOME/.bashrc\n",
    "\n",
    "source $HOME/.bashrc\n",
    "BCFtools plugin usage requires environment variable BCFTOOLS_PLUGINS exported, e.g:\n",
    "Command\n",
    "echo export BCFTOOLS_PLUGINS=/path/to/bcftools/plugins \\\n",
    ">> $HOME/.bashrc\n",
    "\n",
    "source $HOME/.bashrc\n",
    "\n",
    "1.1.3 Install the R packages\n",
    "Once R is installed, for instance the 'data.table' package can be installed in R, e.g.:\n",
    "Command\n",
    "install.packages('data.table', type = 'source', \n",
    "repos = 'http://Rdatatable.github.io/data.table')\n",
    " \n",
    " \n",
    "1.2. Reference genome and genetic map files\n",
    " \n",
    "1.2.1 Fasta files\n",
    "Homo Sapiens assembly hg38 version 0 is used and the required files are:\n",
    "\n",
    "    Homo_sapiens_assembly38.fasta\n",
    "    Homo_sapiens_assembly38.fasta.fai\n",
    "\n",
    "The files are available for downloading at Broad Insitute storage in Google cloud at: https://console.cloud.google.com/storage/browser/broad-references/hg38/v0/?pli=1\n",
    " \n",
    "If you prefer GRCh37/hg19, the reference genome files are available for downloading at Ensembl site at\n",
    "https://grch37.ensembl.org/index.html \n",
    " \n",
    " \n",
    "\n",
    "1.2.2. Genetic map files for phasing with Eagle\n",
    "Genetic map file (all chromosomes in a single file) with recombination frequencies for GRCh38/hg38 are available for downloading at Eagle download page at:\n",
    "https://data.broadinstitute.org/alkesgroup/Eagle/downloads/tables/\n",
    "\n",
    "    genetic_map_hg38_withX.txt.gz\n",
    "\n",
    "\n",
    "We have processed the file according to the command below in order to split it per chromosome with correct headers.\n",
    "The resulting files are saved as:\n",
    "\n",
    "    eagle_chr#_b38.txt (where # is the chromosome number)\n",
    "\n",
    "Command\n",
    "\n",
    "for CHR in {1..23}; do\n",
    "    zcat genetic_map_hg38_withX.txt.gz | \\\n",
    "    grep ^${CHR} | \\\n",
    "\n",
    "Note: Currently the chromosome notation in the Eagle genetic map files is only the chromosome number without 'chr' and chrX is '23'. Starting from Eagle v2.4, also chromosome notation with 'chr' tag is supported.\n",
    " \n",
    "If you prefer GRCh37/hg19, the genetic map file is available for downloading at Eagle download page at https://data.broadinstitute.org/alkesgroup/Eagle/downloads/tables/\n",
    "\n",
    "    genetic_map_hg19_withX.txt.gz\n",
    "\n",
    " \n",
    " \n",
    "\n",
    "1.2.3 Genetic map files for imputation with Beagle\n",
    "Genetic map files fro Beagle are available for downloading at Beagle download page at\n",
    "http://bochet.gcc.biostat.washington.edu/beagle/genetic_maps/\n",
    "\n",
    "    plink.GRCh38.map.zip\n",
    "\n",
    "\n",
    "Unzip the files and change the chromosome notation from PLINK format (only number or X) to GRCh38/hg38 standard notation with 'chr' tag as follows:\n",
    "Command\n",
    "\n",
    "# Unzip the files\n",
    "unzip plink.GRCh38.map.zip\n",
    "# Rename chromosome 23\n",
    "\n",
    "Note: For GRCh38/hg38, the chromosome notation in the Beagle genetic map files is 'chr#' and chromosome 23 is 'chrX'.\n",
    " \n",
    "If you prefer GRCh37/hg19, the genetic map file is available for downloading at Beagle site:\n",
    "http://bochet.gcc.biostat.washington.edu/beagle/genetic_maps/\n",
    "\n",
    "    plink.GRCh37.map.zip\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1.3. Imputation reference panel files\n",
    " \n",
    "1.3.1 Obtain the reference panel files\n",
    "For increased imputation accuracy, we recommend using a population-specific imputation reference panel, if available.\n",
    " \n",
    "If population-specific reference data is not available, for instance 1000 Genomes Project (1000 GP) (www.nature.com/articles/nature15393) data can be used instead.\n",
    " \n",
    "GRCh38/hg38 files are available at EBI 1000 genomes ftp site: ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/supporting/GRCh38_positions/\n",
    "GRCh37/hg19 files are available at Beagle site already processed to be compatible with Beagle:\n",
    "http://bochet.gcc.biostat.washington.edu/beagle/1000_Genomes_phase3_v5a/b37.bref/\n",
    " \n",
    "The 1000 GP files can be downloaded for instance with command:\n",
    "Command\n",
    "wget http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/supporting/GRCh38_positions/ALL.chr{{1..22},X}_GRCh38.genotypes.20170504.vcf.gz{,.tbi}\n",
    "\n",
    "NOTE: \n",
    "The reference panel files should contain: \n",
    "\n",
    "    phased genotypes,\n",
    "    chromosome names with 'chr' and chromosome X as 'chrX', \n",
    "    all variants as biallelic records,\n",
    "    only SNPs and INDELs,\n",
    "    only unique variants, \n",
    "    non-missing data, \n",
    "    chrX as diploid genotypes, and\n",
    "    only unique IDs\n",
    "\n",
    " \n",
    "If your reference panel files are not in the correct format, see some suggested processing commands below.\n",
    "\n",
    "1.3.2 Minimum quality control\n",
    "\n",
    "Here, we have piped most of the processing steps together in order to save significant amount of time by avoiding writing out multiple intermediate files. If your imputation reference panel does not require all the steps, modify the command accordingly.\n",
    "\n",
    "For 1000GP data:\n",
    "\n",
    "    Generate a text file containing space-spearated old and new chromosome names. This is required to rename the numerical chromosome names with 'chr' tag. Apply the new chromosome names with 'bcftools annotate'.\n",
    "    Remove the rare variants, here singletons and doubletons by setting AC threshold with 'bcftools view'.\n",
    "    Split multiallelic sites to biallelic records with 'bcftools norm'.\n",
    "    Keep only SNPs and INDELs with 'bcftools view'. Here, the 1000GP data included a tag VT in the INFO field and data contain also structural variants which should be excluded.\n",
    "    Align the variants to reference genome with 'bcftools norm' in order to have the REF and ALT alleles in the shortest possible representation and to confirm that the REF allele matches the reference genome, additionally remove duplicate variants (-d none).\n",
    "    After alignment, remove multiallelic records with 'bcftools view', since these are formed during the alignment if the REF does not match with the reference genome.\n",
    "    Finally, remove sites containing missing data with 'bcftools view'.\n",
    "\n",
    "\n",
    "Command\n",
    "\n",
    "# Generate a chromosome renaming file\n",
    "for CHR in {1..23} X ; do \n",
    "    echo ${CHR} chr${CHR}\n",
    "\n",
    "\n",
    "If multiallelic sites are present in your data, in order to preserve them throughout the protocol, set ID field with unique IDs e.g. in format CHR_POS_REF_ALT. (RSIDs might contain duplicates, when the multiallelic sites are decomposed.)\n",
    "Command\n",
    "\n",
    "for CHR in {1..23}; do\n",
    "    bcftools annotate \\\n",
    "    --set-id '%CHROM\\_%POS\\_%REF\\_%ALT' \\\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1.3.3 Convert haploid genotypes to homozygous diploids\n",
    "Often chrX is represented as haploid genotypes for males, however, Beagle can only handle diploid genotypes. \n",
    "The command here produces unphased diploid genotypes. But since the haploid genotypes are in diploid format as REF/REF or ALT/ALT, we can simply set the phase for those alleles with a simple sed replacement. \n",
    "\n",
    "The chrX ploidy can be corrected as follows:\n",
    "Command\n",
    "\n",
    "# Fix the chromosome X ploidy to phased diploid\n",
    "# Requires a ploidy.txt file containing \n",
    "# space-separated CHROM,FROM,TO,SEX,PLOIDY \n",
    "\n",
    "\n",
    "1.3.4 Duplicate ID removal\n",
    "Remove duplicate IDs. If you wish to preserve all multiallelic sites, replace the ID column with a unique ID e.g. CHR_POS_REF_ALT (as indicated in Step 1.3.2). \n",
    "\n",
    "Here, 1000GP did not contain multiallelic sites after AC filtering, and thus, RSIDs were preserved in the ID column. And since RSIDs are not always unique, duplicates should be removed.\n",
    "Command\n",
    "\n",
    "for CHR in {1..23}; do\n",
    "    bcftools query -f '%ID\\n' 1000GP_chr${CHR}.vcf.gz | \\\n",
    "    sort | uniq -d > 1000GP_chr${CHR}.dup_id\n",
    "\n",
    " \n",
    "\n",
    "1.3.5 Reference panel allele frequencies\n",
    "Generate a tab-delimited file of the reference panel allele frequencies, one variant per line, with columns CHR, SNP (in format CHR_POS_REF_ALT), REF, ALT, AF (including the header line).\n",
    "\n",
    "First, update (or add) AF values in the INFO field, calculate it with BCFtools plugin +fill-tags:\n",
    "Command\n",
    "\n",
    "# Check if the VCF does NOT contain AF in the INFO field,\n",
    "# and calculate it with bcftools +fill-tags plugin\n",
    "for CHR in {1..23}; do\n",
    "\n",
    "Extract the wanted fields from each VCF file and combine as a single output file with the header:\n",
    "Command\n",
    "\n",
    "# Generate a tab-delimited header\n",
    "echo -e 'CHR\\tSNP\\tREF\\tALT\\tAF' \\\n",
    "    > 1000GP_imputation_all.frq\n",
    "\n",
    "Note: Chromosome notation in the panel.frq file should follow the GRCh38/hg38 notations ('chr#' for autosomal chromosomes and 'chrX' for chromosome 23).\n",
    " \n",
    "\n",
    "\n",
    "1.3.6 Create binary reference panel files\n",
    "The phased reference panel files per chromosome are required in bref format (bref = binary reference). For more information, see Beagle documentation at Beagle site:\n",
    "https://faculty.washington.edu/browning/beagle/bref.16Dec15.pdf.\n",
    " \n",
    "The required bref.*.jar is downloaded from Beagle site:\n",
    "Command\n",
    "wget https://faculty.washington.edu/browning/beagle/bref.27Jan18.7e1.jar\n",
    " \n",
    "Use the processed imputation reference panel VCFs as inputs for the example command below. \n",
    "The output files have the suffix '.bref' instead of '.vcf.gz'.\n",
    "Command\n",
    "\n",
    "# Convert each file to bref format\n",
    "for CHR in {1..23}; do\n",
    "    java -jar /path/to/bref.27Jan18.7e1.jar \\\n",
    "\n",
    "\n",
    "\n",
    "1.3.7 Generate a list of the reference panel sample IDs\n",
    "List of sample IDs present in the reference panel, one line per sample ID can be generated from any of the VCF files as in the example below (assuming that all chromosomes contain the same set of samples):\n",
    "Command\n",
    "bcftools query -l 1000GP_AF_chr22.vcf.gz \\\n",
    "    > 1000GP_sample_IDs.txt\n",
    "\n",
    "\n",
    "1.4. You are ready to start! \n",
    "As the last prepatory step, let's go over the required input data file(s) and also expected final output files!\n",
    " \n",
    "1.4.1 Input file:\n",
    " \n",
    "Post-QC chip genotype data in VCFv4.2 format and chrX genotypes as diploid genotypes:\n",
    "\n",
    "    DATASET.vcf.gz\n",
    "\n",
    " \n",
    "Note: Chromosome notation should follow the GRCh38/hg38 notations (e.g. 'chr#' for autosomal chromosomes, 'chrX', 'chrY' and 'chrM').\n",
    "\n",
    "Note: If the input data was lifted over from an older genome build to build version 38, cautious inspection of the data is highly recommended before proceeding with the protocol.\n",
    "\n",
    "Note: If chrX is represented as haploid genotypes, follow step 1.3.3 first 'bcftools +fixploidy' command (not the other two piped commands) to convert to diploid genotypes.\n",
    " \n",
    " \n",
    "1.4.2 Final output files:\n",
    "\n",
    "    DATASET_imputed_info_chr#.vcf.gz (where # is chromosome number)\n",
    "    DATASET_postimputation_summary_plots.pdf\n",
    "\n",
    "\n",
    "Note: Several intermediate files are created during the protocol. Those files can be used for troubleshooting and deleted once the successful imputation is confirmed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppp_env_x86",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd125518df18430d0936e52ecb7291e22b91211acfd52c6d5373b9b07bdacec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
