{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ?. structure\n",
    "ive downloaded the program structure into the environment snowflakes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "from pgpipe import four_gamete, vcf_split_pysam, vcf_to_ima, vcf_filter, vcf_calc, vcf_sampler, vcf_phase, stat_sampler, vcf_split, vcf_utilities, vcf_to_treemix, model_creator\n",
    "from pgpipe.logging_module import initLogger\n",
    "from pgpipe.informative_loci_filter import filter_bed_regions\n",
    "from pgpipe.subtract_bed import filter_stat\n",
    "import pysam\n",
    "\n",
    "print (\"Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/josephinelovemachine\n",
      "/Users/josephinelovemachine/soyadapt_data_analysis\n",
      "home directory defined\n"
     ]
    }
   ],
   "source": [
    "#define project name\n",
    "#project_name = 'projectname'\n",
    "project_name = 'soyadapt_data_analysis' # [ ] \n",
    "\n",
    "import os.path\n",
    "path = '/Users/josephinelovemachine'\n",
    "full_path = os.path.expanduser(path)\n",
    "print (full_path)\n",
    "# set home directory\n",
    "# ~/<projectname>/\n",
    "home_dir = os.path.join( full_path, project_name)\n",
    "print (home_dir)\n",
    "print (\"home directory defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (215423722.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/1h/nb7x81q15l172nmf3p9pct640000gp/T/ipykernel_24927/215423722.py\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    ******#Define start data file and data name:\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Set up directories and filepaths, run on all restarts\n",
    "config_dir = home_dir + '/config/'\n",
    "results_dir = home_dir + '/results/'\n",
    "workflow_dir = home_dir + '/workflow/' \n",
    "notebook_dir = workflow_dir + '/notebooks/' #WHE RE THIS NOTEBOOK SHOULD BE [ ]\n",
    "# my working dir is where my data is ~/project_name/resources/\n",
    "work_dir = home_dir + '/resources/'\n",
    "#start data files:'\n",
    "data_dir= work_dir +'start_data/' # my start data is here\n",
    "#generated data files:\n",
    "data_generated = work_dir + 'generated_data/'\n",
    "#generated data files:\n",
    "logfile = data_generated+'logfiles/'\n",
    "\n",
    "#                 ****** this needs to change everywhere! ******\n",
    "#Define start data name and location:\n",
    "# data names are set to data _ name _ *** (e.g. data_name_snp)\n",
    "# data locations are set to data _ *** _ datatype (e.g. data_snp_vcf)\n",
    "#Which data do you want to use?\n",
    "data_name_snp = 'soysnp50k' \n",
    "data_snp_vcf = data_dir+'soysnp50k.vcf.gz' \n",
    "data_name_test = 'test_data' \n",
    "data_test_vcf = data_dir+'test_data.vcf.gz' \n",
    "data_name_intersection = 'intersection_data'\n",
    "data_intersection_vcf = data_dir+'intersection_data.vcf.gz' \n",
    "data_name_imputed = 'imputed_data'\n",
    "data_imputed_vcf = data_dir+'imputed_data.vcf.gz' \n",
    "\n",
    "#Metadata\n",
    "\n",
    "#chromosomes list\n",
    "list_vcf_name_chr = data_dir+'soysnp50k_list_vcf_name_chr'\n",
    "# string of all 20 chromosomes named chr\n",
    "chr_all = data_dir+'chr.txt' \n",
    "# The 50k snps list \n",
    "list_snp_locations_50k = data_dir+'soysnp50k_ist_snp_locations_50k'\n",
    "# metadata list:\n",
    "list_vcf_name_country = data_dir+'soysnp50k_list_vcf_name_country'\n",
    "list_vcf_name_maturitygroup = data_dir+'soysnp50k_list_vcf_name_maturitygroup'\n",
    "#list of accessions + population(CCA/SA/Founders) + country + maturity group\n",
    "list_vcf_name_collected = data_dir+'soysnp50k_list_vcf_name_collected'\n",
    "#data files lists so they are named accordingly when generated or added to the project:\n",
    "list_vcf_name_sa= data_dir+'soysnp50k_list_vcf_name_sa'\n",
    "list_vcf_name_cca= data_dir+'soysnp50k_list_vcf_name_cca'\n",
    "list_vcf_name_founders= data_dir+'soysnp50k_list_vcf_name_founders'\n",
    "\n",
    "loci=50000\n",
    "# print check directories and files\n",
    "print(work_dir)\n",
    "print(data_dir)\n",
    "print(data_generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "move this notebook now to the notebook directory\n"
     ]
    }
   ],
   "source": [
    "#Set up directory structure, only needs to be run once\n",
    "if not os.path.exists(config_dir):\n",
    "    os.makedirs(config_dir)\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "if not os.path.exists(workflow_dir):\n",
    "    os.makedirs(workflow_dir)\n",
    "if not os.path.exists(notebook_dir):\n",
    "    os.makedirs(notebook_dir)            \n",
    "if not os.path.exists(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "if not os.path.exists(work_dir+'generated_data/'):\n",
    "    os.makedirs(work_dir+'generated_data/')\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(work_dir+'start_data/')\n",
    "if not os.path.exists(data_generated):\n",
    "    os.makedirs(data_generated)\n",
    "if not os.path.exists(data_generated+'logfiles/'):\n",
    "    os.makedirs(data_generated+'logfiles/')\n",
    "# add files for the project that dont need and workflow access\n",
    "if not os.path.exists(workflow_dir+'envs/'): # envs for each workflow\n",
    "    os.makedirs(workflow_dir+'envs/')\n",
    "if not os.path.exists(workflow_dir+'scripts/'): # scripts for the project like R scripts\n",
    "    os.makedirs(workflow_dir+'scripts/')\n",
    "if not os.path.exists(workflow_dir+'notebooks/'): # this notebook is here! move now! \n",
    "    os.makedirs(workflow_dir+'notebooks/')\n",
    "if not os.path.exists(workflow_dir+'reports/'): # if not in logfile, then here\n",
    "    os.makedirs(workflow_dir+'reports/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a file with accessions, names, country, maturity \n",
    "Model files generation\n",
    "chr.txt. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to try a cluster analysis with: \n",
    "\n",
    "from the PPP workflow Using the program ADMIXTURE Version 1.3.0\n",
    "\n",
    "admixture.py: \n",
    "\n",
    "Automates the estimation of individual ancestries using Admixture. The functions allows for input as: i) Binary-PED files or ii) PED 12-formatted files. The function is also capable of configuring the optional arguments of Admixture.\n",
    "\n",
    "vcf_format_conversions.py: VCF to Plink/EIGENSTRAT\n",
    "\n",
    "Automates various simple file conversions. Currently the function is capable of converting between VCF-based formats (i.e. VCF, compressed-VCF, and BCF) and PLINK-based formats (i.e. PED and Binary-PED). Additional formats will be added as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vcf_format_conversions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1h/nb7x81q15l172nmf3p9pct640000gp/T/ipykernel_24927/809487644.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvcf_format_conversions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mvcf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain_vcf_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_generated\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'vcf2ped'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogfile\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_vcf2ped_conversions.log'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'vcf_format_conversions' is not defined"
     ]
    }
   ],
   "source": [
    "vcf_format_conversions.run([--vcf, main_vcf_data, --output, data_generated+data_name+'vcf2ped', --log, logfile+data_name+'_vcf2ped_conversions.log'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppp_env_x86",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd125518df18430d0936e52ecb7291e22b91211acfd52c6d5373b9b07bdacec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
