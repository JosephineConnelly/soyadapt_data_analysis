{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup project \n",
    "step_1_startfile.ipynb\n",
    "# 2. Merge data for analysis \n",
    "step_2_merge.ipynb\n",
    "# 3. Filter \n",
    "step_3_filter.ipynb\n",
    "# 4. Generation of metadata\n",
    "step_4_metadata_file_generation copy.ipynb\n",
    "create model\n",
    "scripts to generate input files from VCF files\n",
    "# 5. PCA in R\n",
    "\n",
    "# 7. Cluster analysis\n",
    "\n",
    "# 8. Calculate fst, pi, theta and LD in R\n",
    "8_calculate_R in R_project_soy/workflow_scripts\n",
    "\n",
    "calculate Tajimad D  statistics in VCFtools with PPP\n",
    "step_8_calculate.ipynb\n",
    "\n",
    "# 9. \n",
    "Allele frequence differentation (like Fst) at genes\tXP-CLR\n",
    "step_9_xpclr\n",
    "\n",
    "# 10.\n",
    "Analyse structural variation in genes of different accessions.\n",
    "\n",
    "step_10_xpclr.ipynb\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "1. project name is <soyadapt_data_analysis>\n",
    "\n",
    "# project structure\n",
    "\n",
    "project name is <soyadapt_data_analysis>\n",
    "\n",
    "    ├── .gitignore\n",
    "    ├── README.md\n",
    "    ├── LICENSE.md\n",
    "    ├── .vscode\n",
    "    │   ├── settings.json\n",
    "    ├── results\n",
    "    ├── resources\n",
    "    │   ├── start_data (no bigger than 100MB!!)\n",
    "    |   │   ├── tree.txt\n",
    "    |   │   ├── Population_name_two.txt\n",
    "    |   │   ├── Population_name_one.txt\n",
    "    |   │   ├── pop.txt\n",
    "    |   │   ├── METADATA_soybean_resequencing_MQ30.md\n",
    "    |   │   └── accessions.xlsx\n",
    "    |   └── generated_data\n",
    "    |   │   └── logfiles\n",
    "    ├── workflow\n",
    "    │   ├── envs\n",
    "    |   │   ├── environment_make #step by step how i made the environments in this repository.)\n",
    "    |   │   ├── pp_env_x86.yaml\n",
    "    |   │   └── pp_env_x86.txt\n",
    "    │   ├── scripts\n",
    "    |   │   ├── some-script1.py\n",
    "    |   │   └── some-script.R\n",
    "    │   ├── notebooks\n",
    "    |   │   ├── step_1_startfile.ipynb\n",
    "    |   │   ├── step_2_merge.ipynb\n",
    "    |   │   ├── step_2_merge_2.ipynb\n",
    "    |   │   ├── step_3_filter.ipynb\n",
    "    |   │   ├── step_4 metadata_file_generation.ipynb\n",
    "    |   │   ├── step_8_calculate.ipynb\n",
    "    |   │   ├── file_conversion.ipynb\n",
    "    |   │   ├── out.model\n",
    "    |   │   └── step_8_calculate_R.r.ipynb\n",
    "    │   ├── reports\n",
    "    |   │   ├── some-plot1.rst\n",
    "    |   │   └── some-plot2.rst\n",
    "    |   └── gwsfile\n",
    "    ├── config\n",
    "    │   ├── README.md\n",
    "    │   ├── some-config.yaml\n",
    "    │   └── some-sheet.tsv\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "Make environment and install needed programs on my mac M2:\n",
    "I am working in an environment where im only using the old architecture/platform osx-64 when creating a new conda environment because the new arm64 doesent have all the programs i might need. \n",
    "\n",
    "#depenpencies are from: https://ppp.readthedocs.io/en/latest/PPP_pages/install.html\n",
    "\n",
    "CONDA_SUBDIR=osx-64 conda create -n ppp_env_x86 python=3.7.7 pysam\n",
    "conda activate ppp_env_x86\n",
    "conda config --env --set subdir osx-64\n",
    "mamba install -c jaredgk -c bioconda py-popgen\n",
    "\n",
    "which VCFtools\n",
    "which BCFtools \n",
    "which Samtools\n",
    "which HTSlib\n",
    "which plink 1.9\n",
    "which plink 2.0\n",
    "which SHAPEIT\n",
    "which Beagle 5.0\n",
    "which Picard\n",
    "\n",
    "mamba install VCFtools\n",
    "mamba install BCFtools \n",
    "mamba install Samtools\n",
    "mamba install HTSlib\n",
    "#mamba install plink=1.9 #two versions?!\n",
    "#mamba install plink=2.0\n",
    "#mamba install SHAPEIT4 only for linux!\n",
    "mamba install Beagle\n",
    "mamba install Picard\n",
    "\n",
    "on the linux server\n",
    "conda create -n ppp_env python=3.7.7 pysam\n",
    "conda activate ppp_env\n",
    "mamba install -c jaredgk -c bioconda py-popgen\n",
    "mamba install VCFtools\n",
    "mamba install BCFtools \n",
    "mamba install Samtools\n",
    "mamba install HTSlib\n",
    "#mamba install plink=1.9 #two versions?!\n",
    "#mamba install plink=2.0\n",
    "mamba install SHAPEIT4\n",
    "mamba install Beagle\n",
    "mamba install Picard\n",
    "\n",
    "*i have also made an alternative soyadapt_env_x86*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checks:\n",
    "[ ] Make sure all <project_name = 'projectname'> is set to the projects name (in this case its soyadapt_data_analysis)\n",
    "[ ] whats the name of my data?  set at data_name = collected_start_data for example."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure dependencies and env are as it should be."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ppp_env_x86.yaml / soyadapt_env_x86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "from pgpipe import four_gamete, vcf_split_pysam, vcf_to_ima, vcf_filter, vcf_calc, vcf_sampler, vcf_phase, stat_sampler, vcf_split, vcf_utilities, vcf_to_treemix, model_creator\n",
    "from pgpipe.logging_module import initLogger\n",
    "from pgpipe.informative_loci_filter import filter_bed_regions\n",
    "from pgpipe.subtract_bed import filter_stat\n",
    "import pysam\n",
    "\n",
    "print (\"Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define project name\n",
    "#project_name = 'projectname'\n",
    "project_name = 'soyadapt_data_analysis' # [ ] \n",
    "\n",
    "import os.path\n",
    "path = '/Users/josephinelovemachine'\n",
    "full_path = os.path.expanduser(path)\n",
    "print (full_path)\n",
    "# set home directory\n",
    "# ~/<projectname>/\n",
    "home_dir = os.path.join( full_path, project_name)\n",
    "print (home_dir)\n",
    "print (\"home directory defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up directories and filepaths, run on all restarts\n",
    "config_dir = home_dir + '/config/'\n",
    "results_dir = home_dir + '/results/'\n",
    "workflow_dir = home_dir + '/workflow/' \n",
    "notebook_dir = workflow_dir + '/notebooks/' #WHE RE THIS NOTEBOOK SHOULD BE [ ]\n",
    "# my working dir is where my data is ~/project_name/resources/\n",
    "work_dir = home_dir + '/resources/'\n",
    "#start data files:'\n",
    "data_dir= work_dir +'start_data/' # my main_vcf_data is here\n",
    "#generated data files:\n",
    "data_generated = work_dir + 'generated_data/'\n",
    "#generated data files:\n",
    "logfile = data_generated+'logfiles/'\n",
    "\n",
    "#Define start data name and location:\n",
    "# data names are set to data _ name _ *** (e.g. data_name_snp)\n",
    "# data locations are set to data _ *** _ datatype (e.g. data_snp_vcf)\n",
    "#Which data do you want to use?\n",
    "data_name_snp = 'soysnp50k' \n",
    "data_snp_vcf = data_dir+'soysnp50k.vcf.gz' \n",
    "data_name_test = 'test_data' \n",
    "data_test_vcf = data_dir+'test_data.vcf.gz' \n",
    "data_name_intersection = 'intersection_data'\n",
    "data_intersection_vcf = data_dir+'intersection_data.vcf.gz' \n",
    "data_name_imputed = 'imputed_data'\n",
    "data_imputed_vcf = data_dir+'imputed_data.vcf.gz' \n",
    "\n",
    "# ADDED Metadata from start\n",
    "#chromosomes list\n",
    "list_vcf_name_chr = data_dir+'soysnp50k_list_vcf_name_chr'\n",
    "# string of all 20 chromosomes named chr\n",
    "chr_all = data_dir+'chr.txt' \n",
    "# The 50k snps list \n",
    "list_snp_locations_50k = data_dir+'soysnp50k_ist_snp_locations_50k'\n",
    "# metadata list:\n",
    "list_vcf_name_country = data_dir+'soysnp50k_list_vcf_name_country'\n",
    "list_vcf_name_maturitygroup = data_dir+'soysnp50k_list_vcf_name_maturitygroup'\n",
    "#list of accessions + population(CCA/SA/Founders) + country + maturity group\n",
    "list_vcf_name_collected = data_dir+'soysnp50k_list_vcf_name_collected'\n",
    "#data files lists so they are named accordingly when generated or added to the project:\n",
    "list_vcf_name_sa= data_dir+'soysnp50k_list_vcf_name_sa'\n",
    "list_vcf_name_cca= data_dir+'soysnp50k_list_vcf_name_cca'\n",
    "list_vcf_name_founders= data_dir+'soysnp50k_list_vcf_name_founders'\n",
    "\n",
    "loci=50000\n",
    "# print check directories and files\n",
    "print(work_dir)\n",
    "print(data_dir)\n",
    "print(data_generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up directory structure, only needs to be run once\n",
    "if not os.path.exists(config_dir):\n",
    "    os.makedirs(config_dir)\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "if not os.path.exists(workflow_dir):\n",
    "    os.makedirs(workflow_dir)\n",
    "if not os.path.exists(notebook_dir):\n",
    "    os.makedirs(notebook_dir)            \n",
    "if not os.path.exists(work_dir):\n",
    "    os.makedirs(work_dir)\n",
    "if not os.path.exists(work_dir+'generated_data/'):\n",
    "    os.makedirs(work_dir+'generated_data/')\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(work_dir+'start_data/')\n",
    "if not os.path.exists(data_generated):\n",
    "    os.makedirs(data_generated)\n",
    "if not os.path.exists(data_generated+'logfiles/'):\n",
    "    os.makedirs(data_generated+'logfiles/')\n",
    "# add files for the project that dont need and workflow access\n",
    "if not os.path.exists(workflow_dir+'envs/'): # envs for each workflow\n",
    "    os.makedirs(workflow_dir+'envs/')\n",
    "if not os.path.exists(workflow_dir+'scripts/'): # scripts for the project like R scripts\n",
    "    os.makedirs(workflow_dir+'scripts/')\n",
    "if not os.path.exists(workflow_dir+'notebooks/'): # this notebook is here! move now! \n",
    "    os.makedirs(workflow_dir+'notebooks/')\n",
    "if not os.path.exists(workflow_dir+'repots/'): # if not in logfile, then here\n",
    "    os.makedirs(workflow_dir+'reports/')\n",
    "\n",
    "print('move this notebook now to the notebook directory')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For workflows in R see github <JosephineConnelly/R-project-soy>\n",
    "The next steps in the work flow will be as follows\n",
    "\n",
    "2. If the data needs to be merged then in will be according to step_2_merge\n",
    "3. then the data quality will be checked in BCFtools and R\n",
    "4. model files generate\n",
    "5. The PCA will be done in R. \n",
    "6. Cluster analysis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppp_env_x86",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd125518df18430d0936e52ecb7291e22b91211acfd52c6d5373b9b07bdacec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
